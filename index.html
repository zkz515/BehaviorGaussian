<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" 
        content="BehaviorGaussian: Diverse Future Scene Synthesis via Agent Behavior Modeling and 3D Gaussian Splatting">
 
  <meta name="keywords" content="Gaussian Splatting, Simulation, Autonomous Driving">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Behavior Gaussian</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">BehaviorGaussian: Diverse Future Scene Synthesis via Agent Behavior Modeling and 3D Gaussian Splatting</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
             <span class="author-block">
              Kaizhao Zhang<sup>1</sup>,</span>
            <span class="author-block">
              Tian Niu<sup>1</sup>,</span>
            <span class="author-block">
              Ke Wu<sup>1</sup>,</span>
            <span class="author-block">
              Xiangyun Ren<sup>2</sup>,</span>
            <span class="author-block">
              Zhongxue Gan<sup>1</sup>,</span>
            <span class="author-block">
              Wenchao Ding<sup>1</sup>
            </div>

                  <div class="is-size-5 publication-authors">
                          <span class="author-block"><sup>1</sup>Fudan University,</span>
                          <span class="author-block"><sup>2</sup>Chongqing Changan Automobile CO., Ltd.</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2112.0877d6.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/zkz515/BehaviorGaussian" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -2rem;">
  <div class="container is-max-desktop">

<!-- Cover -->
<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">
    <img src="./static/images/cover.png"
        class="interpolation-image"
        alt="Cover Image."/>
      <div class="content has-text-justified">
        <p>
        We propose BehaviorGaussian, a novel framework that integrates 3D Gaussian reconstruction with behavior-aware trajectory prediction for autonomous driving simulation. 
        Our approach first reconstructs photorealistic environments through Gaussian splatting, then generates diverse future scenarios by predicting and simulating multiple agent trajectories within the reconstructed 3D space. 
        This unified pipeline enables parallel simulation of diverse future scene synthesis, facilitating data generation for autonomous driving systems under various behavioral conditions.
        </p>
      </div>
  </div>
</div>
<!-- End cover-->

<!-- Paper abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width box">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Autonomous driving simulation is critical for closed-loop validation of autonomous driving systems. 
          In recent years, the development of NeRF and 3DGS technologies has enabled high-fidelity reconstruction and novel view synthesis, making it possible to bridge the sim2real gap in terms of image realism. 
          This study presents a compact framework integrating scene-separated 3DGS reconstruction with trajectory prediction models.
          BehaviorGaussian explicitly models dynamic object interactions to forecast agent trajectories, which are then unified with reconstructed environments for multi-scenario 3D world simulation. 
          The 3DGS rendering pipeline concurrently generates visualizations of these parallel scenarios through temporally coherent video sequences. 
          Experimental validation on the Waymo dataset confirms our framework's capability to simulate 3D parallel environments effectively, enhancing both simulation authenticity and functional versatility for autonomous driving system development.
          </p>
        </div>
      </div>
    </div>
<!-- End paper abstract -->

<!-- Pipeline -->
<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">
  <h2 class="title is-3">Framework</h2>
    <img src="./static/images/pip_pip.png"
        class="interpolation-image"
        alt="System Architecture Pipeline."/>
    <div class="content has-text-justified">
      <p>
      Illustration of the comprehensive pipeline of our proposed framework for dynamic scene reconstruction and parallel scenario simulation. 
      The diagram consists of three main components: 
      </p>
      <p>
      (1) Scene Reconstruction Module, which takes multimodal inputs including LiDAR point clouds, camera images to generate a decomposed 3D Gaussian representation of the environment, separating static backgrounds, dynamic agents, and sky regions; 
      </p>
      <p>
      (2) Trajectory Prediction Module, which utilizes historical agent trajectories and HD map priors to generate multiple plausible future trajectories for each agent;
      </p>
      <p>
      (3) Parallel Scenario Simulation, where predicted trajectories are integrated into the reconstructed 3D scene to synthesize photorealistic video sequences of diverse future scenarios.
      </p>
    </div>
  </div>
</div>
<!-- End pipeline -->


<!-- Video -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/video_new.mp4"
                    type="video/mp4">
        </div>
      </div>
    </div>
<!--End video -->

  

</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
